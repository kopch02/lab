{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузите выборку Wine по адресу https://archive.ics.uci.edu/ml/machinelearning-databases/wine/wine.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Извлеките из данных признаки и классы. Класс записан в первом\n",
    "столбце (три варианта), признаки — в столбцах со второго по последний. Более подробно о сути признаков можно прочитать по адресу https://archive.ics.uci.edu/ml/datasets/Wine (см. также файл\n",
    "wine.names, приложенный к заданию)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0     1.0  \n",
       "1                          3.40   1050.0     1.0  \n",
       "2                          3.17   1185.0     1.0  \n",
       "3                          3.45   1480.0     1.0  \n",
       "4                          2.93    735.0     1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine=load_wine()\n",
    "\n",
    "data=pd.DataFrame(data=np.c_[wine['data'],wine['target']],columns=wine['feature_names']+['target'])\n",
    "data['target'] = data['target'] + 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data['target']\n",
    "features = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Оценку качества необходимо провести методом кросс-валидации по\n",
    "5 блокам (5-fold). Создайте генератор разбиений, который перемешивает выборку перед формированием блоков (shuffle=True). Для\n",
    "3\n",
    "воспроизводимости результата, создавайте генератор KFold с фиксированным параметром random_state=42. В качестве меры качества используйте долю верных ответов (accuracy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Найдите точность классификации на кросс-валидации для метода\n",
    "k ближайших соседей (sklearn.neighbors.KNeighborsClassifier), при\n",
    "k от 1 до 50. При каком k получилось оптимальное качество? Чему\n",
    "оно равно (число в интервале от 0 до 1)? Данные результаты и\n",
    "будут ответами на вопросы 1 и 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.77777778, 0.66666667, 0.72222222, 0.71428571, 0.77142857]),\n",
       " array([0.72222222, 0.63888889, 0.69444444, 0.57142857, 0.68571429]),\n",
       " array([0.80555556, 0.61111111, 0.63888889, 0.65714286, 0.82857143]),\n",
       " array([0.75      , 0.52777778, 0.61111111, 0.65714286, 0.74285714]),\n",
       " array([0.72222222, 0.61111111, 0.61111111, 0.68571429, 0.74285714]),\n",
       " array([0.72222222, 0.63888889, 0.63888889, 0.68571429, 0.68571429]),\n",
       " array([0.69444444, 0.58333333, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.72222222, 0.61111111, 0.66666667, 0.65714286, 0.74285714]),\n",
       " array([0.72222222, 0.63888889, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.72222222, 0.61111111, 0.63888889, 0.68571429, 0.74285714]),\n",
       " array([0.75      , 0.63888889, 0.66666667, 0.71428571, 0.74285714]),\n",
       " array([0.72222222, 0.66666667, 0.69444444, 0.68571429, 0.71428571]),\n",
       " array([0.72222222, 0.69444444, 0.66666667, 0.65714286, 0.71428571]),\n",
       " array([0.72222222, 0.66666667, 0.72222222, 0.6       , 0.68571429]),\n",
       " array([0.75      , 0.72222222, 0.69444444, 0.62857143, 0.71428571]),\n",
       " array([0.72222222, 0.63888889, 0.72222222, 0.6       , 0.71428571]),\n",
       " array([0.77777778, 0.72222222, 0.72222222, 0.6       , 0.68571429]),\n",
       " array([0.77777778, 0.61111111, 0.69444444, 0.6       , 0.71428571]),\n",
       " array([0.77777778, 0.63888889, 0.69444444, 0.6       , 0.68571429]),\n",
       " array([0.77777778, 0.61111111, 0.69444444, 0.62857143, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.75      , 0.62857143, 0.71428571]),\n",
       " array([0.77777778, 0.63888889, 0.69444444, 0.62857143, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.72222222, 0.6       , 0.77142857]),\n",
       " array([0.77777778, 0.63888889, 0.75      , 0.62857143, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.75      , 0.62857143, 0.71428571]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.65714286, 0.71428571]),\n",
       " array([0.77777778, 0.63888889, 0.72222222, 0.62857143, 0.71428571]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.63888889, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.58333333, 0.72222222, 0.62857143, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.61111111, 0.75      , 0.68571429, 0.74285714]),\n",
       " array([0.83333333, 0.61111111, 0.75      , 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.66666667, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.83333333, 0.61111111, 0.69444444, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.77777778, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.74285714]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.75      , 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.83333333, 0.61111111, 0.72222222, 0.71428571, 0.71428571]),\n",
       " array([0.75      , 0.61111111, 0.72222222, 0.68571429, 0.71428571]),\n",
       " array([0.80555556, 0.61111111, 0.72222222, 0.68571429, 0.71428571])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = []\n",
    "for k in range(1, 51):\n",
    "    model = KNeighborsClassifier(k)\n",
    "    scores.append(cross_val_score(model, features, classes, cv=cv, scoring='accuracy'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\tmean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     0.730476\n",
       "34    0.724603\n",
       "35    0.724603\n",
       "48    0.719048\n",
       "36    0.713492\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(scores, index=np.arange(1, 51))\n",
    "res = res.mean(axis=1)\n",
    "res = res.sort_values(ascending=False)\n",
    "print('k\\tmean')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Произведите масштабирование признаков с помощью функции\n",
    "sklearn.preprocessing.scale. Снова найдите оптимальное k на кроссвалидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "features = scale(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Какое значение k получилось оптимальным после приведения признаков к одному масштабу? Как изменилось значение качества?\n",
    "Приведите ответы на вопросы 3 и 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.94444444, 0.94444444, 0.91666667, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.88888889, 0.91666667, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.91666667, 0.94444444, 0.94285714, 0.94285714]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.91428571, 0.97142857]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.94285714, 0.97142857]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.94285714, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.91428571, 1.        ]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.91666667, 0.94444444, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 1.        ]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.94444444, 0.97222222, 0.97142857, 1.        ]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.94444444, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.88888889, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.88888889, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.94444444, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([1.        , 0.91666667, 0.97222222, 0.97142857, 0.97142857]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.94444444, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.97222222, 0.91666667, 0.97222222, 0.97142857, 0.94285714]),\n",
       " array([0.97222222, 0.94444444, 0.97222222, 0.97142857, 0.94285714])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for k in range(1, 51):\n",
    "    model = KNeighborsClassifier(k)\n",
    "    scores.append(cross_val_score(model, features, classes, cv=cv, scoring='accuracy'))   \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "точность увеличилась, узнаем при каком k будет лучшая точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\tmean\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29    0.977619\n",
       "16    0.972063\n",
       "15    0.972063\n",
       "17    0.966508\n",
       "20    0.966508\n",
       "22    0.966508\n",
       "18    0.966508\n",
       "28    0.966349\n",
       "41    0.966349\n",
       "33    0.966349\n",
       "34    0.966349\n",
       "14    0.966349\n",
       "45    0.966349\n",
       "43    0.966349\n",
       "21    0.960952\n",
       "11    0.960952\n",
       "23    0.960952\n",
       "32    0.960794\n",
       "35    0.960794\n",
       "26    0.960794\n",
       "36    0.960794\n",
       "30    0.960794\n",
       "38    0.960794\n",
       "39    0.960794\n",
       "10    0.960794\n",
       "9     0.960794\n",
       "40    0.960794\n",
       "42    0.960794\n",
       "44    0.960635\n",
       "50    0.960635\n",
       "19    0.955397\n",
       "31    0.955238\n",
       "25    0.955238\n",
       "24    0.955238\n",
       "37    0.955238\n",
       "12    0.955238\n",
       "8     0.955238\n",
       "27    0.955238\n",
       "3     0.955079\n",
       "49    0.955079\n",
       "47    0.955079\n",
       "48    0.949524\n",
       "46    0.949524\n",
       "7     0.949524\n",
       "6     0.949524\n",
       "13    0.949524\n",
       "5     0.949365\n",
       "1     0.943968\n",
       "4     0.938254\n",
       "2     0.932857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_m = pd.DataFrame(scores, index=np.arange(1, 51))\n",
    "res_m = res_m.mean(axis=1)\n",
    "res_m = res_m.sort_values(ascending=False)\n",
    "print('k\\tmean')\n",
    "res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "прирост в точности после масштабирования: 0.25927\n"
     ]
    }
   ],
   "source": [
    "difference = np.round(np.mean(res_m - res), 5)\n",
    "print(f'прирост в точности после масштабирования: {difference}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
